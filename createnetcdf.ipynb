{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NetCDF file from PNBOIA data\n",
    "- NetCDF file with raw and processd data\n",
    "- Developed by Henrique P P Pereira\n",
    "- 21/03/2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create nc from atmosmarine processed wave data using raw time series (HNE)\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "#read processed wave data\n",
    "\n",
    "arq_rig = {}\n",
    "arq_rig['desc'] = 'PNBOIA - Rio Grande Buoy'\n",
    "arq_rig['filename'] = 'rig_8_lioc.csv'\n",
    "arq_rig['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/rio_grande/proc/'\n",
    "arq_rig['outputname'] = 'rig_summary.nc'\n",
    "arq_rig['lat1'] = -31.566\n",
    "arq_rig['lon1'] = -49.966\n",
    "\n",
    "arq_fln = {}\n",
    "arq_fln['desc'] = 'PNBOIA - Florianopolis Buoy'\n",
    "arq_fln['filename'] = 'fln_8_lioc.csv'\n",
    "arq_fln['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/florianopolis/proc/'\n",
    "arq_fln['outputname'] = 'fln_summary.nc'\n",
    "arq_fln['lat1'] = -28.500\n",
    "arq_fln['lon1'] = -47.366\n",
    "\n",
    "arq_san = {}\n",
    "arq_san['desc'] = 'PNBOIA - Santos Buoy'\n",
    "arq_san['filename'] = 'san_8_lioc.csv'\n",
    "arq_san['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/santos/proc/'\n",
    "arq_san['outputname'] = 'san_summary.nc'\n",
    "arq_san['lat1'] = -25.283\n",
    "arq_san['lon1'] = -44.933\n",
    "\n",
    "arq_rcf = {}\n",
    "arq_rcf['desc'] = 'PNBOIA - Recife Buoy'\n",
    "arq_rcf['filename'] = 'rcf_8_lioc.csv'\n",
    "arq_rcf['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/recife/proc/'\n",
    "arq_rcf['outputname'] = 'rcd_summary.nc'\n",
    "arq_rcf['lat1'] = -08.149\n",
    "arq_rcf['lon1'] = -34.560\n",
    "\n",
    "arq = arq_rig\n",
    "\n",
    "dd = pd.read_csv(arq['pathname'] + arq['filename'], parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Write netCDF file\n",
    "dataset = nc.Dataset(arq['pathname'] + arq['outputname'], 'w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "# Create dimensions\n",
    "time = dataset.createDimension('time', None)\n",
    "\n",
    "# Create variables\n",
    "date = dataset.createVariable('date', np.float32, ('time'))\n",
    "date.setncatts({'long_name': u\"Date\",\\\n",
    "               'units':     u\"hours since 0001-01-01 00:00:00.0\"})\n",
    "\n",
    "depth = dataset.createVariable('depth', np.float32, ('time'))\n",
    "depth.setncatts({'long_name': u\"Depth of moored\",\\\n",
    "               'units':     u\"Meters\"})\n",
    "\n",
    "lat = dataset.createVariable('lat', np.float32, ('time'))\n",
    "date.setncatts({'long_name': u\"Latitude\",\\\n",
    "               'units':     u\"Decimal degrees\"})\n",
    "\n",
    "lon = dataset.createVariable('lon', np.float32, ('time')) \n",
    "date.setncatts({'long_name': u\"Longitude\",\\\n",
    "               'units':     u\"Decimal degrees\"})\n",
    "\n",
    "hm0 = dataset.createVariable('hm0', np.float64, ('time'))\n",
    "hm0.setncatts({'long_name': u\"Significant Wave Height\",\\\n",
    "               'units':     u\"Meters\"})\n",
    "\n",
    "tp = dataset.createVariable('tp', np.float32, ('time'))\n",
    "tp.setncatts({'long_name': u\"Peak Period\",\\\n",
    "              'units':     u\"Seconds\"})\n",
    "\n",
    "dp = dataset.createVariable('dp', np.float32, ('time'))\n",
    "dp.setncatts({'long_name': u\"Peak Direction\",\\\n",
    "               'units':     u\"Degrees\"})\n",
    "\n",
    "hs = dataset.createVariable('hs', np.float32, ('time'))\n",
    "hs.setncatts({'long_name': u\"1/10 of Heighest Wave\",\\\n",
    "               'units':     u\"Meters\"})\n",
    "\n",
    "h10 = dataset.createVariable('h10', np.float32, ('time'))\n",
    "h10.setncatts({'long_name': u\"1/10 of Heighest Wave\",\\\n",
    "               'units':     u\"Meters\"})\n",
    "\n",
    "hmax = dataset.createVariable('hmax', np.float32, ('time'))\n",
    "hmax.setncatts({'long_name': u\"Maximum Wave Height\",\\\n",
    "               'units':     u\"Meters\"})\n",
    "\n",
    "thmax = dataset.createVariable('thmax', np.float32, ('time'))\n",
    "thmax.setncatts({'long_name': u\"Period of Maximum Wave Height\",\\\n",
    "                 'units':     u\"Seconds\"})\n",
    "\n",
    "tmed = dataset.createVariable('tmed', np.float32, ('time'))\n",
    "tmed.setncatts({'long_name': u\"Mean Zero Crossing Wave Period\",\\\n",
    "               'units':      u\"Seconds\"})\n",
    "\n",
    "tzamax = dataset.createVariable('tzamax', np.float32, ('time'))\n",
    "tzamax.setncatts({'long_name': u\"Maximum Zero Crossing Wave Period\",\\\n",
    "                 'units':     u\"Seconds\"})\n",
    "\n",
    "# Global Attributes\n",
    "dataset.description = [ arq['desc'] + '\\n', \n",
    "                       '8 degrees of freedom \\n',\n",
    "                       'Axys Buoy']\n",
    "dataset.history = 'Created ' + datetime.ctime(datetime.now())\n",
    "dataset.source = 'Create NetCDF file - PNBOIA'\n",
    "dataset.Conventions='CF-1.6'\n",
    "\n",
    "# Variable Attributes\n",
    "date.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "date.calendar = 'gregorian'\n",
    "\n",
    "# Put data into variable\n",
    "lat[:] = arq['lat1']\n",
    "lon[:] = arq['lon1']\n",
    "date[:] = nc.date2num(list(dd.index), units=date.units, calendar=date.calendar)\n",
    "hm0[:] = dd.hm0.values\n",
    "tp[:] = dd.tp.values\n",
    "dp[:] = dd.dp.values\n",
    "hs[:] = dd.hs.values\n",
    "h10[:] = dd.h10.values\n",
    "hmax[:] = dd.hmax.values\n",
    "thmax[:] = dd.thmax.values\n",
    "tmed[:] = dd.tmed.values\n",
    "tzamax[:] = dd.tzamax.values\n",
    "\n",
    "dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "- Processed internaly in the buoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outputname': 'rig_summary.nc', 'lat1': -31.566, 'filename': 'rig_summary.txt', 'pathname': '/home/hp/Dropbox/pnboia/data/proc/', 'lon1': -49.966, 'desc': 'PNBOIA - Rio Grande Buoy'}\n",
      "{'outputname': 'fln_summary.nc', 'lat1': -28.5, 'filename': 'fln_summary.txt', 'pathname': '/home/hp/Dropbox/pnboia/data/proc/', 'lon1': -47.366, 'desc': 'PNBOIA - Florianopolis Buoy'}\n",
      "{'outputname': 'san_summary.nc', 'lat1': -25.283, 'filename': 'san_summary.txt', 'pathname': '/home/hp/Dropbox/pnboia/data/proc/', 'lon1': -44.933, 'desc': 'PNBOIA - Santos Buoy'}\n",
      "{'outputname': 'rcf_summary.nc', 'lat1': -8.149, 'filename': 'rcf_summary.txt', 'pathname': '/home/hp/Dropbox/pnboia/data/proc/', 'lon1': -34.56, 'desc': 'PNBOIA - Recife Buoy'}\n"
     ]
    }
   ],
   "source": [
    "#create nc from triaxys process - summary file\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "#read processed wave data\n",
    "\n",
    "arq_rig = {}\n",
    "arq_rig['desc'] = 'PNBOIA - Rio Grande Buoy'\n",
    "arq_rig['filename'] = 'rig_summary.txt'\n",
    "arq_rig['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/proc/'\n",
    "arq_rig['outputname'] = 'rig_summary.nc'\n",
    "arq_rig['lat1'] = -31.566\n",
    "arq_rig['lon1'] = -49.966\n",
    "\n",
    "arq_fln = {}\n",
    "arq_fln['desc'] = 'PNBOIA - Florianopolis Buoy'\n",
    "arq_fln['filename'] = 'fln_summary.txt'\n",
    "arq_fln['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/proc/'\n",
    "arq_fln['outputname'] = 'fln_summary.nc'\n",
    "arq_fln['lat1'] = -28.500\n",
    "arq_fln['lon1'] = -47.366\n",
    "\n",
    "arq_san = {}\n",
    "arq_san['desc'] = 'PNBOIA - Santos Buoy'\n",
    "arq_san['filename'] = 'san_summary.txt'\n",
    "arq_san['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/proc/'\n",
    "arq_san['outputname'] = 'san_summary.nc'\n",
    "arq_san['lat1'] = -25.283\n",
    "arq_san['lon1'] = -44.933\n",
    "\n",
    "arq_rcf = {}\n",
    "arq_rcf['desc'] = 'PNBOIA - Recife Buoy'\n",
    "arq_rcf['filename'] = 'rcf_summary.txt'\n",
    "arq_rcf['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/proc/'\n",
    "arq_rcf['outputname'] = 'rcf_summary.nc'\n",
    "arq_rcf['lat1'] = -08.149\n",
    "arq_rcf['lon1'] = -34.560\n",
    "\n",
    "for arq in [arq_rig, arq_fln, arq_san, arq_rcf]:\n",
    "    \n",
    "    print arq\n",
    "\n",
    "    ax = np.loadtxt(arq['pathname'] + arq['filename'], skiprows = 1, usecols = (range(2,18)))\n",
    "    ax_data = np.loadtxt(arq['pathname'] + arq['filename'], dtype = str, skiprows = 1, usecols = (0,1))\n",
    "\n",
    "    #deixa datas com numeros inteiros\n",
    "    ano_ax = [int(ax_data[i,0][0:4]) for i in range(len(ax_data))]\n",
    "    mes_ax = [int(ax_data[i,0][5:7]) for i in range(len(ax_data))]\n",
    "    dia_ax = [int(ax_data[i,0][8:10]) for i in range(len(ax_data))]\n",
    "    hora_ax = [int(ax_data[i,1][:2]) for i in range(len(ax_data))]\n",
    "    min_ax = [int(ax_data[i,1][3:]) for i in range(len(ax_data))]\n",
    "\n",
    "    datam_ax = []\n",
    "    for i in range(len(ax_data)):\n",
    "        datam_ax.append(datetime(ano_ax[i],mes_ax[i],dia_ax[i],hora_ax[i],min_ax[i]))\n",
    "\n",
    "    #  0        1            2          3        4        5         6        7            8            9         10     11           12       13      14              15  \n",
    "    #Year/Julian Date/Zero Crossings/Ave. Ht./Ave. Per./Max Ht./Sig. Wave/Sig. Per./Peak Per.(Tp)/Peak Per.(READ)/HM0/Mean Theta/Sigma Theta/ H1/10 / T.H1/10\t/Mean Per.(Tz)\n",
    "\n",
    "    year1, julian_date1, zero_crossings1, ave_ht1, ave_per1, max_ht1, sig_wave1, sig_per1, peak_per1, peak_per_read1, hm01, mean_theta1, sigma_theta1, h_101, th1_101, mean_per1 = ax.T\n",
    "\n",
    "    # Write netCDF file\n",
    "    dataset = nc.Dataset(arq['pathname'] + arq['outputname'], 'w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "    # Create dimensions\n",
    "    time = dataset.createDimension('time', None)\n",
    "\n",
    "    # Create variables\n",
    "    date = dataset.createVariable('date', np.float32, ('time'))\n",
    "    date.setncatts({'long_name': u\"Date\",\\\n",
    "                   'units':     u\"hours since 0001-01-01 00:00:00.0\"})\n",
    "\n",
    "    depth = dataset.createVariable('depth', np.float32, ('time'))\n",
    "    depth.setncatts({'long_name': u\"Depth of moored\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    lat = dataset.createVariable('lat', np.float32, ('time'))\n",
    "    date.setncatts({'long_name': u\"Latitude\",\\\n",
    "                   'units':     u\"Decimal degrees\"})\n",
    "\n",
    "    lon = dataset.createVariable('lon', np.float32, ('time')) \n",
    "    date.setncatts({'long_name': u\"Longitude\",\\\n",
    "                   'units':     u\"Decimal degrees\"})\n",
    "\n",
    "    year = dataset.createVariable('year', np.float64, ('time'))\n",
    "    year.setncatts({'long_name': u\"Year\",\\\n",
    "                    'units':     u\"Year\"})\n",
    "\n",
    "    julian_date = dataset.createVariable('julian_date', np.float64, ('time'))\n",
    "    julian_date.setncatts({'long_name': u\"Julian Date\",\\\n",
    "                    'units':     u\"Days\"})\n",
    "\n",
    "    zero_crossings = dataset.createVariable('zero_crossings', np.float64, ('time'))\n",
    "    zero_crossings.setncatts({'long_name': u\"Numbers of Zero Cossing\",\\\n",
    "                    'units':     u\"conts\"})\n",
    "\n",
    "    ave_ht = dataset.createVariable('ave_ht', np.float64, ('time'))\n",
    "    ave_ht.setncatts({'long_name': u\"Average Height\",\\\n",
    "                    'units':     u\"Meters\"})\n",
    "\n",
    "    ave_per = dataset.createVariable('ave_per', np.float64, ('time'))\n",
    "    ave_per.setncatts({'long_name': u\"Average Period\",\\\n",
    "                    'units':     u\"Seconds\"})\n",
    "\n",
    "    max_ht = dataset.createVariable('max_ht', np.float32, ('time'))\n",
    "    max_ht.setncatts({'long_name': u\"Maximum Wave Height\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    sig_wave = dataset.createVariable('sig_wave', np.float64, ('time'))\n",
    "    sig_wave.setncatts({'long_name': u\"Significant Wave Height\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    sig_per = dataset.createVariable('sig_per', np.float64, ('time'))\n",
    "    sig_per.setncatts({'long_name': u\"Significant Wave Period\",\\\n",
    "                   'units':     u\"Seconds\"})\n",
    "\n",
    "    peak_per = dataset.createVariable('peak_per', np.float32, ('time'))\n",
    "    peak_per.setncatts({'long_name': u\"Peak Period\",\\\n",
    "                  'units':     u\"Seconds\"})\n",
    "\n",
    "    peak_per_read = dataset.createVariable('peak_per_read', np.float32, ('time'))\n",
    "    peak_per_read.setncatts({'long_name': u\"Peak Period Read\",\\\n",
    "                  'units':     u\"Seconds\"})\n",
    "\n",
    "    hm0 = dataset.createVariable('hm0', np.float64, ('time'))\n",
    "    hm0.setncatts({'long_name': u\"Significant Wave Height\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    mean_theta = dataset.createVariable('mean_theta', np.float32, ('time'))\n",
    "    mean_theta.setncatts({'long_name': u\"Peak Direction\",\\\n",
    "                   'units':     u\"Degrees\"})\n",
    "\n",
    "    sigma_theta = dataset.createVariable('sigma_theta', np.float32, ('time'))\n",
    "    sigma_theta.setncatts({'long_name': u\"Direction Spread\",\\\n",
    "                   'units':     u\"Degrees\"})\n",
    "\n",
    "    h_10 = dataset.createVariable('h_10', np.float32, ('time'))\n",
    "    h_10.setncatts({'long_name': u\"1/10 of Heighest Wave\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    th1_10 = dataset.createVariable('th1_10', np.float32, ('time'))\n",
    "    th1_10.setncatts({'long_name': u\"Period of 1/10 Wave\",\\\n",
    "                     'units':     u\"Seconds\"})\n",
    "\n",
    "    mean_per = dataset.createVariable('mean_per', np.float32, ('time'))\n",
    "    mean_per.setncatts({'long_name': u\"Mean Perio\",\\\n",
    "                   'units':      u\"Seconds\"})\n",
    "\n",
    "    # Global Attributes\n",
    "    dataset.description = [ arq['desc'] + '\\n', \n",
    "                           'Processed by Buoy \\n',\n",
    "                           'Axys Buoy']\n",
    "    dataset.history = 'Created ' + datetime.ctime(datetime.now())\n",
    "    dataset.source = 'Create NetCDF file - PNBOIA'\n",
    "    dataset.Conventions='CF-1.6'\n",
    "\n",
    "    # Variable Attributes\n",
    "    date.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "    date.calendar = 'gregorian'\n",
    "\n",
    "    lat[:] = arq['lat1']\n",
    "    lon[:] = arq['lon1']\n",
    "    date[:] = nc.date2num(datam_ax, units=date.units, calendar=date.calendar)\n",
    "    year[:] = year1\n",
    "    julian_date[:] = julian_date1\n",
    "    zero_crossings[:] = zero_crossings1\n",
    "    ave_ht[:] = ave_ht1\n",
    "    ave_per[:] = ave_per1\n",
    "    max_ht[:] = max_ht1\n",
    "    sig_wave[:] = sig_wave1\n",
    "    sig_per[:] = sig_per1\n",
    "    peak_per[:] = peak_per1\n",
    "    peak_per_read[:] = peak_per_read1\n",
    "    hm0[:] = hm01\n",
    "    mean_theta[:] = mean_theta1\n",
    "    sigma_theta[:] = sigma_theta1\n",
    "    h_10[:] = h_101\n",
    "    th1_10[:] = th1_101\n",
    "    mean_per[:] =  mean_per1\n",
    "\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HNE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "\n",
    "#create array (1382 x len(filenames)) with heave, pitch and roll values \n",
    "\n",
    "arq_rig = {}\n",
    "arq_rig['desc'] = 'PNBOIA - Rio Grande Buoy'\n",
    "arq_rig['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/rio_grande/HNE/'\n",
    "arq_rig['outputname'] = 'rig_hne.nc'\n",
    "arq_rig['lat1'] = -31.566\n",
    "arq_rig['lon1'] = -49.966\n",
    "\n",
    "arq_fln = {}\n",
    "arq_fln['desc'] = 'PNBOIA - Florianopolis Buoy'\n",
    "arq_fln['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/florianopolis/HNE/'\n",
    "arq_fln['outputname'] = 'fln_hne.nc'\n",
    "arq_fln['lat1'] = -28.500\n",
    "arq_fln['lon1'] = -47.366\n",
    "\n",
    "arq_san = {}\n",
    "arq_san['desc'] = 'PNBOIA - Santos Buoy'\n",
    "arq_san['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/santos/HNE/'\n",
    "arq_san['outputname'] = 'san_hne.nc'\n",
    "arq_san['lat1'] = -25.283\n",
    "arq_san['lon1'] = -44.933\n",
    "\n",
    "arq_rcf = {}\n",
    "arq_rcf['desc'] = 'PNBOIA - Recife Buoy'\n",
    "arq_rcf['pathname'] = os.environ['HOME'] + '/Dropbox/pnboia/data/recife/HNE/'\n",
    "arq_rcf['outputname'] = 'rcf_hne.nc'\n",
    "arq_rcf['lat1'] = -08.149\n",
    "arq_rcf['lon1'] = -34.560\n",
    "\n",
    "for arq in [arq_rig, arq_fln, arq_san, arq_rcf]:\n",
    "# for arq in [arq_rcf]:\n",
    "\n",
    "\n",
    "    filenames = []\n",
    "    for a in os.listdir(arq['pathname']):\n",
    "        if a.endswith('HNE'):\n",
    "            filenames.append(a)\n",
    "    filenames = np.sort(filenames)\n",
    "        \n",
    "    heavehne = np.zeros((1382, len(filenames)))\n",
    "    dspnshne = np.zeros((1382, len(filenames)))\n",
    "    dspewhne = np.zeros((1382, len(filenames)))\n",
    "    datehne = []\n",
    "\n",
    "    i=-1\n",
    "    for filename in filenames:\n",
    "\n",
    "        t, n1, n2, n3 = np.loadtxt(arq['pathname'] + filename, skiprows = 11, unpack=True)\n",
    "\n",
    "        if len(n1) > 1000:\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            datehne.append(pd.to_datetime(filename, format='%Y%m%d%H%M.HNE'))\n",
    "\n",
    "            heavehne[:len(t),i] = n1\n",
    "            dspnshne[:len(t),i] = n2\n",
    "            dspewhne[:len(t),i] = n3\n",
    "            \n",
    "    heavehne = heavehne[:,:i+1]\n",
    "    dspnshne = dspnshne[:,:i+1]\n",
    "    dspewhne = dspewhne[:,:i+1]\n",
    "\n",
    "    # Write netCDF file\n",
    "    dataset = nc.Dataset(arq['pathname'] + arq['outputname'], 'w', format='NETCDF4_CLASSIC')\n",
    "\n",
    "    # Create dimensions\n",
    "    time = dataset.createDimension('time', len(datehne))\n",
    "    samp = dataset.createDimension('samp', heavehne.shape[0])\n",
    "\n",
    "    # Create variables\n",
    "    date = dataset.createVariable('date', np.float32, ('time'))\n",
    "    date.setncatts({'long_name': u\"Date\",\\\n",
    "                   'units':     u\"hours since 0001-01-01 00:00:00.0\"})\n",
    "\n",
    "    lat = dataset.createVariable('lat', np.float32, ('time'))\n",
    "    date.setncatts({'long_name': u\"Latitude\",\\\n",
    "                   'units':     u\"Decimal degrees\"})\n",
    "\n",
    "    lon = dataset.createVariable('lon', np.float32, ('time')) \n",
    "    date.setncatts({'long_name': u\"Longitude\",\\\n",
    "                   'units':     u\"Decimal degrees\"})\n",
    "\n",
    "    heave = dataset.createVariable('heave', np.float32, ('samp', 'time'))\n",
    "    heave.setncatts({'long_name': u\"Heave time series\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    dspns = dataset.createVariable('dspns', np.float32, ('samp', 'time'))\n",
    "    dspns.setncatts({'long_name': u\"Dsp.NS time series\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    dspew = dataset.createVariable('dspew', np.float32, ('samp', 'time'))\n",
    "    dspew.setncatts({'long_name': u\"Dsp.EW time series\",\\\n",
    "                   'units':     u\"Meters\"})\n",
    "\n",
    "    # Global Attributes\n",
    "    dataset.description = [ arq['desc'] + '\\n', \n",
    "                           'Processed by Buoy \\n',\n",
    "                           'Axys Buoy']\n",
    "    dataset.history = 'Created ' + datetime.ctime(datetime.now())\n",
    "    dataset.source = 'Create NetCDF file - PNBOIA'\n",
    "    dataset.Conventions='CF-1.6'\n",
    "\n",
    "    # Variable Attributes\n",
    "    date.units = \"hours since 0001-01-01 00:00:00.0\"\n",
    "    date.calendar = 'gregorian'\n",
    "\n",
    "    lat[:] = arq['lat1']\n",
    "    lon[:] = arq['lon1']\n",
    "    date[:] = nc.date2num(datehne, units=date.units, calendar=date.calendar)\n",
    "    heave[:] = heavehne\n",
    "    dspns[:] = dspns\n",
    "    dspew[:] = dspew\n",
    "\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rig_hne.nc'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename\n",
    "# filenames[:10]\n",
    "# arq\n",
    "# len(datehne)\n",
    "# nc.date2num(datehne, units=date.units, calendar=date.calendar)\n",
    "# heavehne.shape\n",
    "# heavehne.shape\n",
    "# heave\n",
    "# samp\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
